{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZBJeznx6h9J"
      },
      "source": [
        "# **PyTorch Workflow Exercise**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Glu2fM4dkNlx"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqKhXY26m31s"
      },
      "outputs": [],
      "source": [
        "# Setup device-agnostic code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7HUhxCxjeBx"
      },
      "source": [
        "## **Q1 Create a straight line dataset using the linear regression formula (`weight * X + bias`)**\n",
        "  * Set `weight=0.4` and `bias=0.7` there should be at least 100 datapoints total.\n",
        "  * Split the data into 80% training, 20% testing.\n",
        "  * Plot the training and testing data so it becomes visual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbDG5MV7jhvE"
      },
      "outputs": [],
      "source": [
        "# Create the data parameters\n",
        "\n",
        "\n",
        "# Make X and y using linear regression feature\n",
        "\n",
        "\n",
        "print(f\"Number of X samples: {len(X)}\")\n",
        "print(f\"Number of y samples: {len(y)}\")\n",
        "print(f\"First 10 X & y samples:\\nX: {X[:10]}\\ny: {y[:10]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlwtT1djkmLw"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29iQZFNhlYJ-"
      },
      "outputs": [],
      "source": [
        "# Plot the training and testing data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImZoe3v8jif8"
      },
      "source": [
        "## **Q2 Build a PyTorch model by subclassing `nn.Module`**\n",
        "  * Inside should be a randomly initialized `nn.Parameter()` with `requires_grad=True`, one for `weights` and one for `bias`\n",
        "  * Implement the `forward()` method to compute the linear regression function you used to create the dataset in Q1\n",
        "  * Once you've constructed the model, make an instance of it and check its `state_dict()`\n",
        "  * **Note:** If you'd like to use `nn.Linear()` instead of `nn.Parameter()` you can"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzd__Y5rjtB8"
      },
      "outputs": [],
      "source": [
        "# Create PyTorch linear regression model by subclassing nn.Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LdcDnmOmyQ2"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model and put it to the target device\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6nYOrJhjtfu"
      },
      "source": [
        "## **Q3 Write the training loop with `MSE` as the loss function and `Adam` as optimizer**.\n",
        "  * Set the learning rate of the optimizer to be 0.05 and the parameters to optimize should be the model parameters from the model you created in Q2\n",
        "  * Write a training loop to perform the appropriate training steps for 100 epochs\n",
        "  * The training loop should test the model on the test dataset every 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltvoZ-FWjv1j"
      },
      "outputs": [],
      "source": [
        "# Create the loss function and optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpE83NvNnkdV"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "\n",
        "\n",
        "# Train model for 300 epochs\n",
        "\n",
        "\n",
        "# Send data to target device\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  ### Training\n",
        "\n",
        "  # Put model in train mode\n",
        "\n",
        "\n",
        "  # 1. Forward pass\n",
        "\n",
        "\n",
        "  # 2. Calculate loss\n",
        "\n",
        "\n",
        "  # 3. Zero gradients\n",
        "\n",
        "\n",
        "  # 4. Backpropagation\n",
        "\n",
        "\n",
        "  # 5. Step the optimizer\n",
        "\n",
        "\n",
        "  ### Testing\n",
        "\n",
        "  # Print out what's happening\n",
        "  print(f\"Epoch: {epoch} | Train loss: {loss:.3f} | Test loss: {test_loss:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4j4TM18jwa7"
      },
      "source": [
        "## **Q4 Make predictions with the trained model on the test data**\n",
        "  * Visualize these predictions against the original training and testing data (**note:** you may need to make sure the predictions are *not* on the GPU if you want to use non-CUDA-enabled libraries such as matplotlib to plot)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbMPK5Qjjyx_"
      },
      "outputs": [],
      "source": [
        "# Make predictions with the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3BdmQaDpFo8"
      },
      "outputs": [],
      "source": [
        "# Plot the predictions (these may need to be on a specific device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2OnlMWKjzX8"
      },
      "source": [
        "## **Q5 Save your trained model's `state_dict()` to file**\n",
        "  * Create a new instance of your model class you made in 2. and load in the `state_dict()` you just saved to it.\n",
        "  * Perform predictions on your test data with the loaded model and confirm they match the original model predictions from 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgxhgD14qr-i"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# 1. Create models directory\n",
        "\n",
        "\n",
        "# 2. Create model save path\n",
        "\n",
        "# 3. Save the model state dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9vTgiLRrJ7T"
      },
      "outputs": [],
      "source": [
        "# Create new instance of model and load saved state dict (make sure to put it on the target device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UGX3VebrVtI"
      },
      "outputs": [],
      "source": [
        "# Make predictions with loaded model and compare them to the previous\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
